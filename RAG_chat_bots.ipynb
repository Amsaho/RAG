{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install openai pinecone-client langchain"
      ],
      "metadata": {
        "id": "qwzs9WKCMjcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U langchain-community"
      ],
      "metadata": {
        "id": "rAHHk_sjJSfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone\n",
        "\n",
        "pc = Pinecone(api_key=\"pinecone_api_key\")\n",
        "index = pc.Index(\"langchain-chatbot\")"
      ],
      "metadata": {
        "id": "8sgntM-IGK2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U langchain-openai"
      ],
      "metadata": {
        "id": "c8ouyetpJFeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# Example list of documents\n",
        "documents = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"Artificial intelligence is transforming the world.\",\n",
        "    \"Python is a versatile programming language used for various applications.\",\n",
        "    \"Pinecone provides a scalable vector database for machine learning applications.\",\n",
        "    \"OpenAI's GPT-4 model is capable of generating human-like text.\"\n",
        "]\n",
        "\n",
        "# Create embeddings\n",
        "embeddings = OpenAIEmbeddings(api_key='api-key')\n",
        "vectors = []\n",
        "\n",
        "for i, doc in enumerate(documents):\n",
        "    vector = embeddings.embed_query(doc)\n",
        "    vectors.append((f'doc_{i}', vector, {'text': doc}))\n",
        "\n",
        "# Upsert vectors into Pinecone\n",
        "index.upsert(vectors)\n"
      ],
      "metadata": {
        "id": "139K5axaKeEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"User's question\"\n",
        "query_vector = embeddings.embed(query)\n",
        "\n",
        "# Retrieve relevant documents\n",
        "results = index.query(query_vector, top_k=5)\n",
        "relevant_docs = [result['metadata']['text'] for result in results['matches']]\n"
      ],
      "metadata": {
        "id": "GTE0ICawLEIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "context = \" \".join(relevant_docs)\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=f\"Answer the question based on the context: {context}\\n\\nQuestion: {query}\\nAnswer:\",\n",
        "    max_tokens=150\n",
        ")\n",
        "\n",
        "print(response.choices[0].text.strip())\n"
      ],
      "metadata": {
        "id": "R0U6iY2qOONC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/ask', methods=['POST'])\n",
        "def ask():\n",
        "    data = request.json\n",
        "    query = data['question']\n",
        "    query_vector = embeddings.embed(query)\n",
        "    results = index.query(query_vector, top_k=5)\n",
        "    relevant_docs = [result['metadata']['text'] for result in results['matches']]\n",
        "    context = \" \".join(relevant_docs)\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"text-davinci-003\",\n",
        "        prompt=f\"Answer the question based on the context: {context}\\n\\nQuestion: {query}\\nAnswer:\",\n",
        "        max_tokens=150\n",
        "    )\n",
        "    return jsonify({'answer': response.choices[0].text.strip()})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ],
      "metadata": {
        "id": "povBINJzOh7T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}